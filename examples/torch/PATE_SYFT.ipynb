{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "# Learning private models with multiple teachers"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "Protocol:\n",
    "1. Train teachers:\n",
    "    - Devide training set into buckets (not overlapping)\n",
    "    - Train a models (teacher) on each bucket\n",
    "2. Train student:\n",
    "    - Extract a share of the test set\n",
    "    - Ensemble predictions from teachers: queries each teacher for predictions on the test set share\n",
    "    - Aggregate teacher predictions to get student training labels using noising max: it\n",
    "  adds Laplacian noise to label counts and returns the most frequent label\n",
    "    - Train student with the aggregated label\n",
    "    - Validate the student model on the remaining test data\n",
    "\n",
    "http://www.cleverhans.io/privacy/2018/04/29/privacy-and-machine-learning.html\n",
    "https://github.com/tensorflow/models/tree/master/research/differential_privacy/multiple_teachers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.dp.pate import train_teachers, train_student\n",
    "from torchvision import datasets, transforms\n",
    "\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "\n",
    "def prepare_mnist():\n",
    "    kwargs = {\"num_workers\": 1}\n",
    "\n",
    "    train_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            \"./data\",\n",
    "            train=True,\n",
    "            download=True,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=60000,\n",
    "        shuffle=True,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    test_loader = torch.utils.data.DataLoader(\n",
    "        datasets.MNIST(\n",
    "            \"./data\",\n",
    "            train=False,\n",
    "            transform=transforms.Compose(\n",
    "                [transforms.ToTensor(), transforms.Normalize((0.1307,), (0.3081,))]\n",
    "            ),\n",
    "        ),\n",
    "        batch_size=10000,\n",
    "        shuffle=False,\n",
    "        **kwargs,\n",
    "    )\n",
    "\n",
    "    train_data, train_labels = next(iter(train_loader))\n",
    "    test_data, test_labels = next(iter(test_loader))\n",
    "\n",
    "    return train_data, train_labels, test_data, test_labels"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "# For this demo, we use MNIST dataset\n",
    "train_data, train_labels, test_data, test_labels = prepare_mnist()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "0.3.1\n"
     ]
    }
   ],
   "source": [
    "import argparse\n",
    "import torch\n",
    "import torch.nn as nn\n",
    "import torch.nn.functional as F\n",
    "import torch.optim as optim\n",
    "from torch.autograd import Variable\n",
    "from torch.utils.data import TensorDataset, DataLoader\n",
    "\n",
    "print(torch.__version__)\n",
    "# Training settings\n",
    "parser = argparse.ArgumentParser(description='PyTorch Example')\n",
    "parser.add_argument('--batch-size', type=int, default=8, metavar='N',\n",
    "                    help='input batch size for training (default: 8)')\n",
    "parser.add_argument('--test-batch-size', type=int, default=8, metavar='N',\n",
    "                    help='input batch size for testing (default: 8)')\n",
    "parser.add_argument('--epochs', type=int, default=10, metavar='N',\n",
    "                    help='number of epochs to train (default: 10)')\n",
    "parser.add_argument('--lr', type=float, default=0.001, metavar='LR',\n",
    "                    help='learning rate (default: 0.001)')\n",
    "parser.add_argument('--momentum', type=float, default=0.0, metavar='M',\n",
    "                    help='SGD momentum (default: 0.0)')\n",
    "parser.add_argument('--seed', type=int, default=1, metavar='S',\n",
    "                    help='random seed (default: 1)')\n",
    "parser.add_argument('--log-interval', type=int, default=10, metavar='N',\n",
    "                    help='how many batches to wait before logging training status')\n",
    "args = parser.parse_args([])\n",
    "\n",
    "torch.manual_seed(args.seed)\n",
    "kwargs = {}"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "dataset = \"mnist\" \n",
    "nb_labels = 10\n",
    "nb_teachers = 100 \n",
    "stdnt_share = 1000\n",
    "lap_scale = 10"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "metadata": {},
   "outputs": [],
   "source": [
    "import syft as sy\n",
    "from syft import Variable as Var\n",
    "from syft import nn\n",
    "from syft import optim"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "metadata": {},
   "outputs": [],
   "source": [
    "# hook = sy.TorchHook(verbose=False)\n",
    "# me = hook.local_worker\n",
    "# bob = sy.VirtualWorker(id=\"bob\",hook=hook, is_client_worker=False)\n",
    "# alice = sy.VirtualWorker(id=\"alice\",hook=hook, is_client_worker=False)\n",
    "# me.is_client_worker = False\n",
    "\n",
    "# compute_nodes = [bob, alice]\n",
    "\n",
    "# bob.add_workers([alice])\n",
    "# alice.add_workers([bob])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "metadata": {},
   "outputs": [
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Worker 0 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 1 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 2 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 3 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 4 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 5 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 6 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 7 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 8 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 9 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 10 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 11 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 12 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 13 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 14 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 15 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 16 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 17 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 18 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 19 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 20 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 21 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 22 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 23 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 24 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 25 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 26 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 27 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 28 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 29 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 30 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 31 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 32 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 33 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 34 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 35 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 36 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 37 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 38 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 39 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 40 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 41 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 42 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 43 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 44 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 45 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 46 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 47 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 48 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 49 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 50 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 51 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 52 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 53 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 54 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 55 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 56 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 57 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 58 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 59 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 60 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 61 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 62 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 63 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 64 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 65 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 66 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 67 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 68 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 69 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 70 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 71 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 72 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 73 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 74 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 75 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 76 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 77 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 78 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 79 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 80 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 81 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 82 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 83 already exists. Replacing old worker which could cause unexpected behavior\n"
     ]
    },
    {
     "name": "stderr",
     "output_type": "stream",
     "text": [
      "WARNING:root:Worker 84 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 85 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 86 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 87 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 88 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 89 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 90 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 91 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 92 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 93 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 94 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 95 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 96 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 97 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 98 already exists. Replacing old worker which could cause unexpected behavior\n",
      "WARNING:root:Worker 99 already exists. Replacing old worker which could cause unexpected behavior\n"
     ]
    }
   ],
   "source": [
    "hook = sy.TorchHook(verbose=False)\n",
    "me = hook.local_worker\n",
    "\n",
    "compute_nodes = []\n",
    "for i in range(nb_teachers):\n",
    "    compute_nodes.append(sy.VirtualWorker(id=str(i), hook=hook))\n",
    "    \n",
    "for i in range(len(compute_nodes)):\n",
    "#    compute_nodes[i].add_workers([compute_nodes[i+1]])\n",
    "    me.add_worker(compute_nodes[i])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [],
   "source": [
    "#compute_nodes[0].add_workers(compute_nodes[1:])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "from syft.dp.pate import partition_dataset\n",
    "\n",
    "train_distributed_dataset = []\n",
    "\n",
    "for i in range(len(compute_nodes)):\n",
    "    worker_id = int(compute_nodes[i].id)\n",
    "    data, labels = partition_dataset(train_data, train_labels, nb_teachers, worker_id)\n",
    "    data = Variable(data)\n",
    "    labels = Variable(labels.type(torch.LongTensor))\n",
    "    data.send(compute_nodes[worker_id])\n",
    "    labels.send(compute_nodes[worker_id])\n",
    "    train_distributed_dataset.append((data, labels))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "(Variable containing:FloatTensor[_PointerTensor - id:37120276766 owner:me loc:0 id@loc:45432860737],\n",
       " Variable containing:LongTensor[_PointerTensor - id:83876207727 owner:me loc:0 id@loc:5293758686])"
      ]
     },
     "execution_count": 10,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "train_distributed_dataset[0]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "metadata": {},
   "outputs": [],
   "source": [
    "# class CNN_Model(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(CNN_Model, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1, 16, 5, stride = 1)\n",
    "#         #self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.avgpool1 = nn.AvgPool2d(2)\n",
    "#         self.conv2 = nn.Conv2d(16, 16, 5, stride = 1)\n",
    "#         #self.batchnorm2 = nn.BatchNorm2d(16)\n",
    "#         self.relu2 = nn.ReLU()\n",
    "#         self.avgpool2 = nn.AvgPool2d(2)\n",
    "#         self.linear1 = nn.Linear(256, 100)\n",
    "#         #self.batchnorm3 = nn.BatchNorm1d(100)\n",
    "#         self.relu3 = nn.ReLU()\n",
    "#         self.linear2 = nn.Linear(100, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         #x = self.batchnorm1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.avgpool1(x)\n",
    "#         x = self.conv2(x)\n",
    "#         #x = self.batchnorm2(x)\n",
    "#         x = self.relu2(x)\n",
    "#         x = self.avgpool2(x)\n",
    "#         x = x.view(-1, 256)\n",
    "#         x = self.linear1(x)\n",
    "#         #x = self.batchnorm3(x)\n",
    "#         x = self.relu3(x)\n",
    "#         out = self.linear2(x)\n",
    "#         return out\n",
    "    \n",
    "# class CNN_Model(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(CNN_Model, self).__init__()\n",
    "#         self.linear1 = nn.Linear(784, 100)\n",
    "#         self.linear2 = nn.Linear(100, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = x.view(-1, 784)\n",
    "#         x = self.linear1(x)\n",
    "#         out = self.linear2(x)\n",
    "#         return out\n",
    "    \n",
    "    \n",
    "class CNN_Model(nn.Module):\n",
    "    def __init__(self, num_classes):\n",
    "        super(CNN_Model, self).__init__()\n",
    "        self.conv1 = nn.Conv2d(1,16,5,stride=1)\n",
    "        #self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "        self.relu1 = nn.ReLU()\n",
    "        self.avgpool1 = nn.AvgPool2d(2)\n",
    "        self.conv2 = nn.Conv2d(16,16,5,stride=1)\n",
    "        self.linear1 = nn.Linear(1024, 100)\n",
    "        self.linear2 = nn.Linear(100, num_classes)\n",
    "\n",
    "    def forward(self, x):\n",
    "        x = self.conv1(x)\n",
    "        #x = self.batchnorm1(x)\n",
    "        x = self.relu1(x)\n",
    "        x = self.avgpool1(x)\n",
    "        x = self.conv2(x)\n",
    "        x = x.view(-1, 1024)\n",
    "        x = self.linear1(x)\n",
    "        out = self.linear2(x)\n",
    "        return out\n",
    "    \n",
    "# class CNN_Model(nn.Module):\n",
    "#     def __init__(self, num_classes):\n",
    "#         super(CNN_Model, self).__init__()\n",
    "#         self.conv1 = nn.Conv2d(1,16,5,stride=1)\n",
    "#         #self.batchnorm1 = nn.BatchNorm2d(16)\n",
    "#         self.relu1 = nn.ReLU()\n",
    "#         self.avgpool1 = nn.AvgPool2d(2)\n",
    "#         #self.conv2 = nn.Conv2d(16,16,5,stride=1)\n",
    "#         self.linear1 = nn.Linear(2304, 100)\n",
    "#         self.linear2 = nn.Linear(100, num_classes)\n",
    "\n",
    "#     def forward(self, x):\n",
    "#         x = self.conv1(x)\n",
    "#         #x = self.batchnorm1(x)\n",
    "#         x = self.relu1(x)\n",
    "#         x = self.avgpool1(x)\n",
    "#         #x = self.conv2(x)\n",
    "#         x = x.view(-1, 2304)\n",
    "#         x = self.linear1(x)\n",
    "#         out = self.linear2(x)\n",
    "#         return out\n",
    "    \n",
    "model = CNN_Model(10)\n",
    "optimizer = optim.SGD(model.parameters(), lr=args.lr)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 12,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yo = model(Variable(train_data))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 13,
   "metadata": {},
   "outputs": [],
   "source": [
    "#yo.size()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 14,
   "metadata": {},
   "outputs": [],
   "source": [
    "def train(epoch):\n",
    "    model.train()\n",
    "    \n",
    "    for batch_idx, (data,target) in enumerate(train_distributed_dataset):\n",
    "            \n",
    "        worker = data.location\n",
    "        print(worker)\n",
    "        print(data)\n",
    "        model.send(worker)\n",
    "\n",
    "        optimizer.zero_grad()\n",
    "        # update the model\n",
    "        pred = model(data)\n",
    "        loss = F.cross_entropy(pred, target)\n",
    "        loss.backward()\n",
    "        model.get()\n",
    "        optimizer.step()\n",
    "\n",
    "        if batch_idx % args.log_interval == 0:\n",
    "            loss.get()\n",
    "            print(loss)\n",
    "#             print('Train Epoch: {} [{}/{} ({:.0f}%)]\\tLoss: {:.6f}'.format(\n",
    "#                 epoch, batch_idx * args.batch_size, len(train_loader) * args.batch_size,\n",
    "#                 100. * batch_idx / len(train_loader), loss.data[0]))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": 15,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "<syft.core.workers.virtual.VirtualWorker id:0>\n",
      "Variable containing:FloatTensor[_PointerTensor - id:37120276766 owner:me loc:0 id@loc:45432860737]\n"
     ]
    },
    {
     "ename": "Exception",
     "evalue": "Tensor \"18090280626\" not found on worker \"0\"!!!\n\nYou just tried to interact with an object ID:18090280626 on worker 0 which does not exist!!! Use .send() and .get() on all your tensors to make sure they're on the same machines.\n\nIf you think this tensor does exist, check the ._objects dictionary on the worker and see for yourself!!! The most common reason this error happens is because someone calls .get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!",
     "output_type": "error",
     "traceback": [
      "\u001b[0;31m---------------------------------------------------------------------------\u001b[0m",
      "\u001b[0;31mKeyError\u001b[0m                                  Traceback (most recent call last)",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36mget_obj\u001b[0;34m(self, remote_key)\u001b[0m\n\u001b[1;32m    633\u001b[0m         \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 634\u001b[0;31m             \u001b[0mobj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_objects\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mremote_key\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    635\u001b[0m         \u001b[0;32mexcept\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mKeyError\u001b[0m: 18090280626",
      "\nDuring handling of the above exception, another exception occurred:\n",
      "\u001b[0;31mException\u001b[0m                                 Traceback (most recent call last)",
      "\u001b[0;32m<ipython-input-15-29513752496c>\u001b[0m in \u001b[0;36m<module>\u001b[0;34m()\u001b[0m\n\u001b[1;32m      3\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m      4\u001b[0m \u001b[0;32mfor\u001b[0m \u001b[0mepoch\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mrange\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;36m1\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0margs\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mepochs\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;36m1\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m----> 5\u001b[0;31m     \u001b[0mtrain\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mepoch\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m<ipython-input-14-0282749c80f4>\u001b[0m in \u001b[0;36mtrain\u001b[0;34m(epoch)\u001b[0m\n\u001b[1;32m      9\u001b[0m         \u001b[0mmodel\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     10\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 11\u001b[0;31m         \u001b[0moptimizer\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_grad\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     12\u001b[0m         \u001b[0;31m# update the model\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     13\u001b[0m         \u001b[0mpred\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmodel\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/torch/optim/optimizer.py\u001b[0m in \u001b[0;36mzero_grad\u001b[0;34m(self)\u001b[0m\n\u001b[1;32m    114\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m \u001b[0;32mis\u001b[0m \u001b[0;32mnot\u001b[0m \u001b[0;32mNone\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    115\u001b[0m                     \u001b[0;32mif\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mvolatile\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 116\u001b[0;31m                         \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mzero_\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    117\u001b[0m                     \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    118\u001b[0m                         \u001b[0mdata\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mp\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mgrad\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdata\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/hook.py\u001b[0m in \u001b[0;36m_execute_method_call\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    465\u001b[0m             \u001b[0mworker\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mhook_self\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mlocal_worker\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    466\u001b[0m             \u001b[0;32mtry\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 467\u001b[0;31m                 \u001b[0;32mreturn\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_execute_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mattr\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    468\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    469\u001b[0m             \u001b[0;32mexcept\u001b[0m \u001b[0mNotImplementedError\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36m_execute_call\u001b[0;34m(self, attr, self_, *args, **kwargs)\u001b[0m\n\u001b[1;32m   1043\u001b[0m         \u001b[0;31m# performing the operation\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1044\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1045\u001b[0;31m         \u001b[0mresult\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mchild_type\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mhandle_call\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msyft_command\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1046\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1047\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mis_torch_command\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mhandle_call\u001b[0;34m(cls, syft_command, owner)\u001b[0m\n\u001b[1;32m   1033\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1034\u001b[0m             \u001b[0;31m# Else we send the command\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1035\u001b[0;31m             \u001b[0mresponse\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mowner\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_torch_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mlocation\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mcommand\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1036\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1037\u001b[0m         \u001b[0;31m# torch_utils.assert_has_only_torch_tensorvars(response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36msend_torch_command\u001b[0;34m(self, recipient, message)\u001b[0m\n\u001b[1;32m   1154\u001b[0m         \u001b[0;34m*\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mmessage\u001b[0m \u001b[0;34m(\u001b[0m\u001b[0mstring\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m**\u001b[0m \u001b[0mthe\u001b[0m \u001b[0mmessage\u001b[0m \u001b[0mbeing\u001b[0m \u001b[0msent\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1155\u001b[0m         \"\"\"\n\u001b[0;32m-> 1156\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1157\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1158\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0msend_command\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mframework\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0;34m\"torch\"\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36msend_command\u001b[0;34m(self, recipient, message, framework)\u001b[0m\n\u001b[1;32m   1163\u001b[0m         \u001b[0;31m# print(message)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1164\u001b[0m         response = self.send_msg(\n\u001b[0;32m-> 1165\u001b[0;31m             \u001b[0mmessage\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mmessage_type\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mframework\u001b[0m \u001b[0;34m+\u001b[0m \u001b[0;34m\"_cmd\"\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mrecipient\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1166\u001b[0m         )\n\u001b[1;32m   1167\u001b[0m         \u001b[0;31m# print(response)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36msend_msg\u001b[0;34m(self, message, message_type, recipient, profile_mode)\u001b[0m\n\u001b[1;32m    250\u001b[0m         \u001b[0;31m# or other ways of sending messages).\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    251\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mprofile_mode\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 252\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_profiled_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_wrapper_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    253\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_wrapper_json\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    254\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/profiling.py\u001b[0m in \u001b[0;36mwrapper\u001b[0;34m(*args, **kwargs)\u001b[0m\n\u001b[1;32m     56\u001b[0m             \u001b[0mprof\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mcProfile\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mProfile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     57\u001b[0m             \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0menable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m---> 58\u001b[0;31m             \u001b[0mres\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mmthd\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m     59\u001b[0m             \u001b[0mprof\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdisable\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m     60\u001b[0m             \u001b[0mprofile_processing_fun\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mprof\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36m_profiled_send_msg\u001b[0;34m(self, *args, **kwargs)\u001b[0m\n\u001b[1;32m    255\u001b[0m     \u001b[0;34m@\u001b[0m\u001b[0mprofile\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0msave_send_msg_stats\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    256\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0m_profiled_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 257\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_send_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0;34m*\u001b[0m\u001b[0margs\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0;34m**\u001b[0m\u001b[0mkwargs\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    258\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    259\u001b[0m     \u001b[0;32mdef\u001b[0m \u001b[0mcompile_composite_message\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/virtual.py\u001b[0m in \u001b[0;36m_send_msg\u001b[0;34m(self, message_wrapper_json_binary, recipient)\u001b[0m\n\u001b[1;32m    111\u001b[0m         \"\"\"\n\u001b[1;32m    112\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 113\u001b[0;31m         \u001b[0;32mreturn\u001b[0m \u001b[0mrecipient\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mreceive_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_wrapper_json_binary\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36mreceive_msg\u001b[0;34m(self, message_wrapper_json)\u001b[0m\n\u001b[1;32m    312\u001b[0m         \u001b[0;31m# load json into a dictionary where all objects have been deserialized\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    313\u001b[0m         message_wrapper = encode.decode(\n\u001b[0;32m--> 314\u001b[0;31m             \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdecode_msg\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage_wrapper_json\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m=\u001b[0m\u001b[0mself\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    315\u001b[0m         )\n\u001b[1;32m    316\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36mdecode\u001b[0;34m(message, worker, acquire, message_is_dict)\u001b[0m\n\u001b[1;32m    209\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0misinstance\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mdict\u001b[0m\u001b[0;34m)\u001b[0m \u001b[0;32mand\u001b[0m \u001b[0;34m\"mode\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    210\u001b[0m         \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0;32mTrue\u001b[0m \u001b[0;32mif\u001b[0m \u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"mode\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0;34m\"acquire\"\u001b[0m \u001b[0;32melse\u001b[0m \u001b[0;32mFalse\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 211\u001b[0;31m         \u001b[0mmessage\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mdecoder\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmessage\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"obj\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    212\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    213\u001b[0m     \u001b[0;32mif\u001b[0m \u001b[0;34m\"message\"\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mdict_message\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36mpython_decode\u001b[0;34m(self, dct)\u001b[0m\n\u001b[1;32m    326\u001b[0m                     )\n\u001b[1;32m    327\u001b[0m             \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 328\u001b[0;31m                 \u001b[0mdct\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mkey\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mpython_decode\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    329\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mdct\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/encode.py\u001b[0m in \u001b[0;36mpython_decode\u001b[0;34m(self, dct)\u001b[0m\n\u001b[1;32m    300\u001b[0m                 \u001b[0;32mif\u001b[0m \u001b[0mtype_code\u001b[0m \u001b[0;32min\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtensor_codes\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    301\u001b[0m                     return torch.guard[obj_type].deser(\n\u001b[0;32m--> 302\u001b[0;31m                         \u001b[0mobj_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mself\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0macquire\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    303\u001b[0m                     )\n\u001b[1;32m    304\u001b[0m                 \u001b[0;31m# Case of a Variable\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mdeser\u001b[0;34m(obj_type, msg_obj, worker, acquire)\u001b[0m\n\u001b[1;32m   2562\u001b[0m         \u001b[0mchild_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch_utils\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mextract_type_and_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"child\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2563\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 2564\u001b[0;31m         \u001b[0msyft_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_SyftTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeser_routing\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mchild_type\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mchild_obj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   2565\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   2566\u001b[0m         \u001b[0;31m# If syft_obj has a parent, then it's an already existing object, with a legitimate torch wrapper\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mdeser_routing\u001b[0;34m(cls, obj_type, obj, worker, acquire)\u001b[0m\n\u001b[1;32m    257\u001b[0m             \u001b[0;32mreturn\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_LocalTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    258\u001b[0m         \u001b[0;32melif\u001b[0m \u001b[0msyft_code\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mtype_codes\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_PointerTensor\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 259\u001b[0;31m             \u001b[0;32mreturn\u001b[0m \u001b[0msy\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0m_PointerTensor\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mdeser\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mobj\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m,\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    260\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    261\u001b[0m             \u001b[0msyft_type\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mtorch\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mguard\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0mobj_type\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/frameworks/torch/tensor.py\u001b[0m in \u001b[0;36mdeser\u001b[0;34m(cls, msg_obj, worker, acquire)\u001b[0m\n\u001b[1;32m   1099\u001b[0m         \u001b[0;31m# If local, we render the object or syft object\u001b[0m\u001b[0;34m\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1100\u001b[0m         \u001b[0;32mif\u001b[0m \u001b[0mmsg_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"location\"\u001b[0m\u001b[0;34m]\u001b[0m \u001b[0;34m==\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mid\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m-> 1101\u001b[0;31m             \u001b[0msyft_obj\u001b[0m \u001b[0;34m=\u001b[0m \u001b[0mworker\u001b[0m\u001b[0;34m.\u001b[0m\u001b[0mget_obj\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg_obj\u001b[0m\u001b[0;34m[\u001b[0m\u001b[0;34m\"id_at_location\"\u001b[0m\u001b[0;34m]\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m   1102\u001b[0m         \u001b[0;32melse\u001b[0m\u001b[0;34m:\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m   1103\u001b[0m             \u001b[0;32mif\u001b[0m \u001b[0macquire\u001b[0m\u001b[0;34m:\u001b[0m  \u001b[0;31m# If there is data transmission, data being here Pointer\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;32m/anaconda3/lib/python3.6/site-packages/syft-0.1.0-py3.6.egg/syft/core/workers/base.py\u001b[0m in \u001b[0;36mget_obj\u001b[0;34m(self, remote_key)\u001b[0m\n\u001b[1;32m    655\u001b[0m             \u001b[0mmsg\u001b[0m \u001b[0;34m+=\u001b[0m \u001b[0;34m\" Check your code to make sure you haven't already called .get() on this pointer!!!\"\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    656\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0;32m--> 657\u001b[0;31m             \u001b[0;32mraise\u001b[0m \u001b[0mException\u001b[0m\u001b[0;34m(\u001b[0m\u001b[0mmsg\u001b[0m\u001b[0;34m)\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[0m\u001b[1;32m    658\u001b[0m         \u001b[0;32mreturn\u001b[0m \u001b[0mobj\u001b[0m\u001b[0;34m\u001b[0m\u001b[0m\n\u001b[1;32m    659\u001b[0m \u001b[0;34m\u001b[0m\u001b[0m\n",
      "\u001b[0;31mException\u001b[0m: Tensor \"18090280626\" not found on worker \"0\"!!!\n\nYou just tried to interact with an object ID:18090280626 on worker 0 which does not exist!!! Use .send() and .get() on all your tensors to make sure they're on the same machines.\n\nIf you think this tensor does exist, check the ._objects dictionary on the worker and see for yourself!!! The most common reason this error happens is because someone calls .get() on the object's pointer without realizing it (which deletes the remote object and sends it to the pointer). Check your code to make sure you haven't already called .get() on this pointer!!!"
     ]
    }
   ],
   "source": [
    "args.epochs = 10\n",
    "\n",
    "\n",
    "for epoch in range(1, args.epochs + 1):\n",
    "    train(epoch)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.5"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
